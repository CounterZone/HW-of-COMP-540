Training data shape:  (49000, 3072)
Validation data shape:  (1000, 3072)
Test data shape:  (10000, 3072)
Training data shape with bias term:  (49000, 3073)
Validation data shape with bias term:  (1000, 3073)
Test data shape with bias term:  (10000, 3073)
iteration 0 / 8000: loss 13.125330
iteration 100 / 8000: loss 11.621780
iteration 200 / 8000: loss 11.046906
iteration 300 / 8000: loss 10.438440
iteration 400 / 8000: loss 10.155063
iteration 500 / 8000: loss 10.520924
iteration 600 / 8000: loss 9.951017
iteration 700 / 8000: loss 9.952157
iteration 800 / 8000: loss 10.046853
iteration 900 / 8000: loss 10.060189
iteration 1000 / 8000: loss 10.054269
iteration 1100 / 8000: loss 9.476853
iteration 1200 / 8000: loss 9.355760
iteration 1300 / 8000: loss 9.071269
iteration 1400 / 8000: loss 8.973927
iteration 1500 / 8000: loss 8.995171
iteration 1600 / 8000: loss 9.082266
iteration 1700 / 8000: loss 8.707067
iteration 1800 / 8000: loss 8.472869
iteration 1900 / 8000: loss 8.575753
iteration 2000 / 8000: loss 8.476654
iteration 2100 / 8000: loss 8.681629
iteration 2200 / 8000: loss 8.208520
iteration 2300 / 8000: loss 8.434518
	---- FINISHED batch size: 1.000000e+02 learning rate: 1.000000e-07 reg: 5.000000e+04------
iteration 0 / 8000: loss 22.402535
iteration 100 / 8000: loss 18.687568
iteration 200 / 8000: loss 17.981165
	---- FINISHED batch size: 1.000000e+02 learning rate: 1.000000e-07 reg: 1.000000e+05------
iteration 0 / 8000: loss 81.928517
iteration 100 / 8000: loss 72.520020
iteration 200 / 8000: loss 65.545100
iteration 300 / 8000: loss 59.348338
iteration 400 / 8000: loss 53.843719
iteration 500 / 8000: loss 48.610887
iteration 600 / 8000: loss 43.912700
iteration 700 / 8000: loss 39.706657
iteration 800 / 8000: loss 36.266056
iteration 900 / 8000: loss 33.047333
iteration 1000 / 8000: loss 30.047939
iteration 1100 / 8000: loss 27.132178
iteration 1200 / 8000: loss 24.702004
iteration 1300 / 8000: loss 22.579434
iteration 1400 / 8000: loss 20.545678
iteration 1500 / 8000: loss 18.847574
	---- FINISHED batch size: 1.000000e+02 learning rate: 1.000000e-07 reg: 5.000000e+05------
iteration 0 / 8000: loss 157.349278
iteration 100 / 8000: loss 126.876595
iteration 200 / 8000: loss 104.011394
iteration 300 / 8000: loss 85.356192
iteration 400 / 8000: loss 69.836999
iteration 500 / 8000: loss 57.645501
iteration 600 / 8000: loss 47.174737
iteration 700 / 8000: loss 38.994521
iteration 800 / 8000: loss 32.187624
iteration 900 / 8000: loss 26.670493
iteration 1000 / 8000: loss 22.203022
iteration 1100 / 8000: loss 18.518519
	---- FINISHED batch size: 1.000000e+02 learning rate: 1.000000e-07 reg: 1.000000e+06------
iteration 0 / 8000: loss 773.930615
iteration 100 / 8000: loss 283.575057
iteration 200 / 8000: loss 105.166574
iteration 300 / 8000: loss 39.833013
iteration 400 / 8000: loss 15.773415
iteration 500 / 8000: loss 7.095035
iteration 600 / 8000: loss 3.974315
iteration 700 / 8000: loss 2.751154
	---- FINISHED batch size: 1.000000e+02 learning rate: 1.000000e-07 reg: 5.000000e+06------
iteration 0 / 8000: loss 14.257409
iteration 100 / 8000: loss 9.928736
iteration 200 / 8000: loss 9.353305
iteration 300 / 8000: loss 8.823773
iteration 400 / 8000: loss 8.209410
iteration 500 / 8000: loss 8.245207
	---- FINISHED batch size: 1.000000e+02 learning rate: 5.000000e-07 reg: 5.000000e+04------
iteration 0 / 8000: loss 20.797106
iteration 100 / 8000: loss 16.735233
	---- FINISHED batch size: 1.000000e+02 learning rate: 5.000000e-07 reg: 1.000000e+05------
iteration 0 / 8000: loss 81.882165
iteration 100 / 8000: loss 49.102496
iteration 200 / 8000: loss 30.139161
iteration 300 / 8000: loss 18.650620
iteration 400 / 8000: loss 12.046943
iteration 500 / 8000: loss 8.206895
	---- FINISHED batch size: 1.000000e+02 learning rate: 5.000000e-07 reg: 5.000000e+05------
iteration 0 / 8000: loss 161.853102
iteration 100 / 8000: loss 58.325940
iteration 200 / 8000: loss 22.433846
iteration 300 / 8000: loss 9.515000
iteration 400 / 8000: loss 4.640826
	---- FINISHED batch size: 1.000000e+02 learning rate: 5.000000e-07 reg: 1.000000e+06------
iteration 0 / 8000: loss 780.202610
iteration 100 / 8000: loss 6.974360
iteration 200 / 8000: loss 2.103666
iteration 300 / 8000: loss 2.117182
iteration 400 / 8000: loss 2.092839
iteration 500 / 8000: loss 2.143354
iteration 600 / 8000: loss 2.117709
iteration 700 / 8000: loss 2.120649
	---- FINISHED batch size: 1.000000e+02 learning rate: 5.000000e-07 reg: 5.000000e+06------
iteration 0 / 8000: loss 13.560490
	---- FINISHED batch size: 1.000000e+02 learning rate: 1.000000e-06 reg: 5.000000e+04------
iteration 0 / 8000: loss 21.140367
iteration 100 / 8000: loss 15.278765
iteration 200 / 8000: loss 12.284753
iteration 300 / 8000: loss 10.374396
iteration 400 / 8000: loss 8.746906
iteration 500 / 8000: loss 7.454132
iteration 600 / 8000: loss 6.405519
	---- FINISHED batch size: 1.000000e+02 learning rate: 1.000000e-06 reg: 1.000000e+05------
iteration 0 / 8000: loss 83.341000
iteration 100 / 8000: loss 30.356850
iteration 200 / 8000: loss 12.128173
iteration 300 / 8000: loss 5.698418
iteration 400 / 8000: loss 3.337805
iteration 500 / 8000: loss 2.435531
	---- FINISHED batch size: 1.000000e+02 learning rate: 1.000000e-06 reg: 5.000000e+05------
iteration 0 / 8000: loss 159.396919
iteration 100 / 8000: loss 22.217871
iteration 200 / 8000: loss 4.564708
iteration 300 / 8000: loss 2.239641
iteration 400 / 8000: loss 1.955254
iteration 500 / 8000: loss 1.948009
	---- FINISHED batch size: 1.000000e+02 learning rate: 1.000000e-06 reg: 1.000000e+06------
iteration 0 / 8000: loss 767.054338
iteration 100 / 8000: loss 2.131402
iteration 200 / 8000: loss 2.056033
	---- FINISHED batch size: 1.000000e+02 learning rate: 1.000000e-06 reg: 5.000000e+06------
iteration 0 / 8000: loss 12.836149
iteration 100 / 8000: loss 6.874500
iteration 200 / 8000: loss 4.903005
iteration 300 / 8000: loss 3.474144
iteration 400 / 8000: loss 2.933838
iteration 500 / 8000: loss 2.791876
iteration 600 / 8000: loss 2.198900
iteration 700 / 8000: loss 2.169161
iteration 800 / 8000: loss 2.460031
	---- FINISHED batch size: 1.000000e+02 learning rate: 5.000000e-06 reg: 5.000000e+04------
iteration 0 / 8000: loss 21.207954
iteration 100 / 8000: loss 7.620136
iteration 200 / 8000: loss 3.988704
iteration 300 / 8000: loss 2.444777
iteration 400 / 8000: loss 2.309059
	---- FINISHED batch size: 1.000000e+02 learning rate: 5.000000e-06 reg: 1.000000e+05------
iteration 0 / 8000: loss 82.901770
iteration 100 / 8000: loss 2.589887
iteration 200 / 8000: loss 2.061997
	---- FINISHED batch size: 1.000000e+02 learning rate: 5.000000e-06 reg: 5.000000e+05------
iteration 0 / 8000: loss 158.853762
iteration 100 / 8000: loss 2.359081
iteration 200 / 8000: loss 2.047046
iteration 300 / 8000: loss 2.214283
iteration 400 / 8000: loss 2.255554
iteration 500 / 8000: loss 2.140421
iteration 600 / 8000: loss 2.055855
iteration 700 / 8000: loss 2.888835
iteration 800 / 8000: loss 2.375737
iteration 900 / 8000: loss 2.060242
iteration 1000 / 8000: loss 2.474717
iteration 1100 / 8000: loss 2.339895
iteration 1200 / 8000: loss 2.259348
iteration 1300 / 8000: loss 2.385545
iteration 1400 / 8000: loss 2.261607
iteration 1500 / 8000: loss 2.613468
iteration 1600 / 8000: loss 2.329430
iteration 1700 / 8000: loss 2.180396
iteration 1800 / 8000: loss 2.343175
iteration 1900 / 8000: loss 1.866225
iteration 2000 / 8000: loss 2.079046
	---- FINISHED batch size: 1.000000e+02 learning rate: 5.000000e-06 reg: 1.000000e+06------
iteration 0 / 8000: loss 779.438581
iteration 100 / 8000: loss 2.652519
iteration 200 / 8000: loss 2.531610
iteration 300 / 8000: loss 2.413243
iteration 400 / 8000: loss 2.443905
	---- FINISHED batch size: 1.000000e+02 learning rate: 5.000000e-06 reg: 5.000000e+06------
iteration 0 / 8000: loss 9.277870
iteration 100 / 8000: loss 7.897702
iteration 200 / 8000: loss 7.647537
iteration 300 / 8000: loss 7.168897
iteration 400 / 8000: loss 6.884513
	---- FINISHED batch size: 2.000000e+02 learning rate: 1.000000e-07 reg: 5.000000e+04------
iteration 0 / 8000: loss 13.955511
iteration 100 / 8000: loss 11.866789
iteration 200 / 8000: loss 10.837247
iteration 300 / 8000: loss 10.781296
iteration 400 / 8000: loss 10.421816
	---- FINISHED batch size: 2.000000e+02 learning rate: 1.000000e-07 reg: 1.000000e+05------
iteration 0 / 8000: loss 43.371579
iteration 100 / 8000: loss 40.034504
	---- FINISHED batch size: 2.000000e+02 learning rate: 1.000000e-07 reg: 5.000000e+05------
iteration 0 / 8000: loss 84.055724
iteration 100 / 8000: loss 74.082238
iteration 200 / 8000: loss 66.585392
iteration 300 / 8000: loss 60.053158
iteration 400 / 8000: loss 54.548897
iteration 500 / 8000: loss 49.209562
iteration 600 / 8000: loss 44.616236
iteration 700 / 8000: loss 40.377077
iteration 800 / 8000: loss 36.695454
iteration 900 / 8000: loss 33.637068
iteration 1000 / 8000: loss 30.444069
iteration 1100 / 8000: loss 27.510458
iteration 1200 / 8000: loss 25.098532
iteration 1300 / 8000: loss 22.918632
	---- FINISHED batch size: 2.000000e+02 learning rate: 1.000000e-07 reg: 1.000000e+06------
iteration 0 / 8000: loss 385.034893
iteration 100 / 8000: loss 232.802972
iteration 200 / 8000: loss 141.658024
iteration 300 / 8000: loss 86.342204
iteration 400 / 8000: loss 53.030250
iteration 500 / 8000: loss 32.861949
iteration 600 / 8000: loss 20.681298
iteration 700 / 8000: loss 13.340378
iteration 800 / 8000: loss 8.915924
iteration 900 / 8000: loss 6.197223
iteration 1000 / 8000: loss 4.534565
iteration 1100 / 8000: loss 3.525741
iteration 1200 / 8000: loss 2.858566
iteration 1300 / 8000: loss 2.569105
	---- FINISHED batch size: 2.000000e+02 learning rate: 1.000000e-07 reg: 5.000000e+06------
iteration 0 / 8000: loss 8.833077
iteration 100 / 8000: loss 6.811080
	---- FINISHED batch size: 2.000000e+02 learning rate: 5.000000e-07 reg: 5.000000e+04------
iteration 0 / 8000: loss 13.765717
iteration 100 / 8000: loss 10.667969
iteration 200 / 8000: loss 9.602520
iteration 300 / 8000: loss 9.026313
iteration 400 / 8000: loss 8.455003
iteration 500 / 8000: loss 8.450268
	---- FINISHED batch size: 2.000000e+02 learning rate: 5.000000e-07 reg: 1.000000e+05------
iteration 0 / 8000: loss 44.627005
iteration 100 / 8000: loss 33.135377
iteration 200 / 8000: loss 25.861001
iteration 300 / 8000: loss 20.505850
iteration 400 / 8000: loss 16.133020
iteration 500 / 8000: loss 12.929547
iteration 600 / 8000: loss 10.457443
iteration 700 / 8000: loss 8.372210
iteration 800 / 8000: loss 6.847122
iteration 900 / 8000: loss 5.754598
iteration 1000 / 8000: loss 4.855113
	---- FINISHED batch size: 2.000000e+02 learning rate: 5.000000e-07 reg: 5.000000e+05------
iteration 0 / 8000: loss 83.160079
iteration 100 / 8000: loss 49.629717
iteration 200 / 8000: loss 30.563047
iteration 300 / 8000: loss 19.007599
iteration 400 / 8000: loss 12.355482
iteration 500 / 8000: loss 8.189925
iteration 600 / 8000: loss 5.686328
iteration 700 / 8000: loss 4.102108
	---- FINISHED batch size: 2.000000e+02 learning rate: 5.000000e-07 reg: 1.000000e+06------
iteration 0 / 8000: loss 385.100693
iteration 100 / 8000: loss 32.411501
iteration 200 / 8000: loss 4.468282
iteration 300 / 8000: loss 2.206420
	---- FINISHED batch size: 2.000000e+02 learning rate: 5.000000e-07 reg: 5.000000e+06------
iteration 0 / 8000: loss 9.506910
iteration 100 / 8000: loss 6.397001
iteration 200 / 8000: loss 5.936486
	---- FINISHED batch size: 2.000000e+02 learning rate: 1.000000e-06 reg: 5.000000e+04------
iteration 0 / 8000: loss 13.159399
	---- FINISHED batch size: 2.000000e+02 learning rate: 1.000000e-06 reg: 1.000000e+05------
iteration 0 / 8000: loss 43.958498
iteration 100 / 8000: loss 25.580630
iteration 200 / 8000: loss 15.926080
iteration 300 / 8000: loss 10.359496
iteration 400 / 8000: loss 6.874692
iteration 500 / 8000: loss 4.955384
iteration 600 / 8000: loss 3.721271
	---- FINISHED batch size: 2.000000e+02 learning rate: 1.000000e-06 reg: 5.000000e+05------
iteration 0 / 8000: loss 83.790873
iteration 100 / 8000: loss 29.848902
iteration 200 / 8000: loss 12.022158
iteration 300 / 8000: loss 5.563925
iteration 400 / 8000: loss 3.219597
iteration 500 / 8000: loss 2.338982
iteration 600 / 8000: loss 2.129525
iteration 700 / 8000: loss 2.004705
iteration 800 / 8000: loss 1.927383
iteration 900 / 8000: loss 1.884733
iteration 1000 / 8000: loss 1.937024
iteration 1100 / 8000: loss 1.924620
	---- FINISHED batch size: 2.000000e+02 learning rate: 1.000000e-06 reg: 1.000000e+06------
iteration 0 / 8000: loss 390.985119
iteration 100 / 8000: loss 4.444610
	---- FINISHED batch size: 2.000000e+02 learning rate: 1.000000e-06 reg: 5.000000e+06------
iteration 0 / 8000: loss 9.226705
iteration 100 / 8000: loss 5.020727
iteration 200 / 8000: loss 4.269637
iteration 300 / 8000: loss 3.732539
	---- FINISHED batch size: 2.000000e+02 learning rate: 5.000000e-06 reg: 5.000000e+04------
iteration 0 / 8000: loss 13.942817
	---- FINISHED batch size: 2.000000e+02 learning rate: 5.000000e-06 reg: 1.000000e+05------
iteration 0 / 8000: loss 44.666208
iteration 100 / 8000: loss 4.931261
iteration 200 / 8000: loss 2.208196
iteration 300 / 8000: loss 1.947513
iteration 400 / 8000: loss 2.059768
iteration 500 / 8000: loss 1.988823
iteration 600 / 8000: loss 1.988017
	---- FINISHED batch size: 2.000000e+02 learning rate: 5.000000e-06 reg: 5.000000e+05------
iteration 0 / 8000: loss 83.240840
iteration 100 / 8000: loss 2.442206
iteration 200 / 8000: loss 2.146030
	---- FINISHED batch size: 2.000000e+02 learning rate: 5.000000e-06 reg: 1.000000e+06------
iteration 0 / 8000: loss 390.265235
iteration 100 / 8000: loss 2.077726
	---- FINISHED batch size: 2.000000e+02 learning rate: 5.000000e-06 reg: 5.000000e+06------
iteration 0 / 8000: loss 8.544865
iteration 100 / 8000: loss 6.203485
iteration 200 / 8000: loss 5.435066
iteration 300 / 8000: loss 5.656068
iteration 400 / 8000: loss 5.177892
	---- FINISHED batch size: 4.000000e+02 learning rate: 1.000000e-07 reg: 5.000000e+04------
iteration 0 / 8000: loss 9.362676
iteration 100 / 8000: loss 7.866448
iteration 200 / 8000: loss 7.455422
iteration 300 / 8000: loss 7.321000
iteration 400 / 8000: loss 6.969517
iteration 500 / 8000: loss 6.936982
iteration 600 / 8000: loss 6.763819
iteration 700 / 8000: loss 6.601856
iteration 800 / 8000: loss 6.548868
iteration 900 / 8000: loss 6.612605
iteration 1000 / 8000: loss 6.360238
	---- FINISHED batch size: 4.000000e+02 learning rate: 1.000000e-07 reg: 1.000000e+05------
iteration 0 / 8000: loss 25.245702
iteration 100 / 8000: loss 22.597899
	---- FINISHED batch size: 4.000000e+02 learning rate: 1.000000e-07 reg: 5.000000e+05------
iteration 0 / 8000: loss 43.792872
iteration 100 / 8000: loss 40.181039
	---- FINISHED batch size: 4.000000e+02 learning rate: 1.000000e-07 reg: 1.000000e+06------
iteration 0 / 8000: loss 198.508264
iteration 100 / 8000: loss 154.065398
iteration 200 / 8000: loss 119.883156
iteration 300 / 8000: loss 93.755277
iteration 400 / 8000: loss 73.256970
iteration 500 / 8000: loss 57.147580
iteration 600 / 8000: loss 44.888308
iteration 700 / 8000: loss 35.305483
iteration 800 / 8000: loss 27.869103
iteration 900 / 8000: loss 22.153156
iteration 1000 / 8000: loss 17.669664
iteration 1100 / 8000: loss 14.211558
iteration 1200 / 8000: loss 11.383074
iteration 1300 / 8000: loss 9.445790
iteration 1400 / 8000: loss 7.700877
iteration 1500 / 8000: loss 6.380971
	---- FINISHED batch size: 4.000000e+02 learning rate: 1.000000e-07 reg: 5.000000e+06------
iteration 0 / 8000: loss 7.581079
iteration 100 / 8000: loss 4.819704
	---- FINISHED batch size: 4.000000e+02 learning rate: 5.000000e-07 reg: 5.000000e+04------
iteration 0 / 8000: loss 8.906525
iteration 100 / 8000: loss 6.948256
iteration 200 / 8000: loss 6.335843
iteration 300 / 8000: loss 6.118763
	---- FINISHED batch size: 4.000000e+02 learning rate: 5.000000e-07 reg: 1.000000e+05------
iteration 0 / 8000: loss 24.001303
iteration 100 / 8000: loss 19.868774
iteration 200 / 8000: loss 17.203380
iteration 300 / 8000: loss 15.446022
iteration 400 / 8000: loss 13.619443
	---- FINISHED batch size: 4.000000e+02 learning rate: 5.000000e-07 reg: 5.000000e+05------
iteration 0 / 8000: loss 44.839340
iteration 100 / 8000: loss 32.776220
iteration 200 / 8000: loss 25.635894
iteration 300 / 8000: loss 20.310086
iteration 400 / 8000: loss 15.982877
iteration 500 / 8000: loss 12.882222
iteration 600 / 8000: loss 10.353512
iteration 700 / 8000: loss 8.467965
iteration 800 / 8000: loss 6.899367
	---- FINISHED batch size: 4.000000e+02 learning rate: 5.000000e-07 reg: 1.000000e+06------
iteration 0 / 8000: loss 197.220955
iteration 100 / 8000: loss 56.433855
iteration 200 / 8000: loss 17.379854
iteration 300 / 8000: loss 6.326298
iteration 400 / 8000: loss 3.191029
	---- FINISHED batch size: 4.000000e+02 learning rate: 5.000000e-07 reg: 5.000000e+06------
iteration 0 / 8000: loss 8.295588
iteration 100 / 8000: loss 4.493765
	---- FINISHED batch size: 4.000000e+02 learning rate: 1.000000e-06 reg: 5.000000e+04------
iteration 0 / 8000: loss 9.757101
iteration 100 / 8000: loss 6.365094
	---- FINISHED batch size: 4.000000e+02 learning rate: 1.000000e-06 reg: 1.000000e+05------
iteration 0 / 8000: loss 25.113341
iteration 100 / 8000: loss 17.356304
iteration 200 / 8000: loss 13.668034
iteration 300 / 8000: loss 10.934314
iteration 400 / 8000: loss 8.784272
	---- FINISHED batch size: 4.000000e+02 learning rate: 1.000000e-06 reg: 5.000000e+05------
iteration 0 / 8000: loss 44.479681
iteration 100 / 8000: loss 25.396136
iteration 200 / 8000: loss 15.890789
iteration 300 / 8000: loss 10.274146
iteration 400 / 8000: loss 6.975605
iteration 500 / 8000: loss 4.867521
iteration 600 / 8000: loss 3.691590
iteration 700 / 8000: loss 2.896806
iteration 800 / 8000: loss 2.544933
	---- FINISHED batch size: 4.000000e+02 learning rate: 1.000000e-06 reg: 1.000000e+06------
iteration 0 / 8000: loss 199.277858
iteration 100 / 8000: loss 17.290252
iteration 200 / 8000: loss 3.243495
	---- FINISHED batch size: 4.000000e+02 learning rate: 1.000000e-06 reg: 5.000000e+06------
iteration 0 / 8000: loss 7.824433
iteration 100 / 8000: loss 3.898544
iteration 200 / 8000: loss 3.386825
	---- FINISHED batch size: 4.000000e+02 learning rate: 5.000000e-06 reg: 5.000000e+04------
iteration 0 / 8000: loss 10.458019
iteration 100 / 8000: loss 5.158498
	---- FINISHED batch size: 4.000000e+02 learning rate: 5.000000e-06 reg: 1.000000e+05------
iteration 0 / 8000: loss 24.745666
iteration 100 / 8000: loss 7.269862
iteration 200 / 8000: loss 3.432920
	---- FINISHED batch size: 4.000000e+02 learning rate: 5.000000e-06 reg: 5.000000e+05------
iteration 0 / 8000: loss 44.778720
iteration 100 / 8000: loss 5.030934
	---- FINISHED batch size: 4.000000e+02 learning rate: 5.000000e-06 reg: 1.000000e+06------
iteration 0 / 8000: loss 195.923841
iteration 100 / 8000: loss 2.076725
iteration 200 / 8000: loss 2.137088
	---- FINISHED batch size: 4.000000e+02 learning rate: 5.000000e-06 reg: 5.000000e+06------
iteration 0 / 8000: loss 6.970091
	---- FINISHED batch size: 8.000000e+02 learning rate: 1.000000e-07 reg: 5.000000e+04------
iteration 0 / 8000: loss 6.804412
iteration 100 / 8000: loss 5.589764
	---- FINISHED batch size: 8.000000e+02 learning rate: 1.000000e-07 reg: 1.000000e+05------
iteration 0 / 8000: loss 14.478450
iteration 100 / 8000: loss 13.519541
	---- FINISHED batch size: 8.000000e+02 learning rate: 1.000000e-07 reg: 5.000000e+05------
iteration 0 / 8000: loss 24.533852
iteration 100 / 8000: loss 22.684626
iteration 200 / 8000: loss 21.709501
	---- FINISHED batch size: 8.000000e+02 learning rate: 1.000000e-07 reg: 1.000000e+06------
iteration 0 / 8000: loss 101.307143
iteration 100 / 8000: loss 88.561014
iteration 200 / 8000: loss 77.879237
iteration 300 / 8000: loss 68.703211
iteration 400 / 8000: loss 60.763967
iteration 500 / 8000: loss 53.709834
iteration 600 / 8000: loss 47.525947
iteration 700 / 8000: loss 42.065579
iteration 800 / 8000: loss 37.278982
iteration 900 / 8000: loss 33.051744
iteration 1000 / 8000: loss 29.327012
iteration 1100 / 8000: loss 26.051583
iteration 1200 / 8000: loss 23.178921
iteration 1300 / 8000: loss 20.679358
iteration 1400 / 8000: loss 18.488224
iteration 1500 / 8000: loss 16.487623
iteration 1600 / 8000: loss 14.739464
iteration 1700 / 8000: loss 13.226154
	---- FINISHED batch size: 8.000000e+02 learning rate: 1.000000e-07 reg: 5.000000e+06------
iteration 0 / 8000: loss 5.902540
iteration 100 / 8000: loss 4.027740
iteration 200 / 8000: loss 3.694793
iteration 300 / 8000: loss 3.629283
iteration 400 / 8000: loss 3.320480
	---- FINISHED batch size: 8.000000e+02 learning rate: 5.000000e-07 reg: 5.000000e+04------
iteration 0 / 8000: loss 7.712481
	---- FINISHED batch size: 8.000000e+02 learning rate: 5.000000e-07 reg: 1.000000e+05------
iteration 0 / 8000: loss 15.084375
iteration 100 / 8000: loss 12.022998
iteration 200 / 8000: loss 10.886168
iteration 300 / 8000: loss 10.293726
	---- FINISHED batch size: 8.000000e+02 learning rate: 5.000000e-07 reg: 5.000000e+05------
iteration 0 / 8000: loss 24.685393
iteration 100 / 8000: loss 19.669907
iteration 200 / 8000: loss 17.303885
iteration 300 / 8000: loss 15.306394
iteration 400 / 8000: loss 13.719469
iteration 500 / 8000: loss 12.104702
iteration 600 / 8000: loss 10.848235
	---- FINISHED batch size: 8.000000e+02 learning rate: 5.000000e-07 reg: 1.000000e+06------
iteration 0 / 8000: loss 100.816693
iteration 100 / 8000: loss 53.077661
iteration 200 / 8000: loss 28.883952
iteration 300 / 8000: loss 16.316218
iteration 400 / 8000: loss 9.545329
iteration 500 / 8000: loss 5.985408
iteration 600 / 8000: loss 4.039529
	---- FINISHED batch size: 8.000000e+02 learning rate: 5.000000e-07 reg: 5.000000e+06------
iteration 0 / 8000: loss 7.433258
iteration 100 / 8000: loss 3.701984
	---- FINISHED batch size: 8.000000e+02 learning rate: 1.000000e-06 reg: 5.000000e+04------
iteration 0 / 8000: loss 8.455915
iteration 100 / 8000: loss 4.633970
	---- FINISHED batch size: 8.000000e+02 learning rate: 1.000000e-06 reg: 1.000000e+05------
iteration 0 / 8000: loss 14.965414
iteration 100 / 8000: loss 10.922880
	---- FINISHED batch size: 8.000000e+02 learning rate: 1.000000e-06 reg: 5.000000e+05------
iteration 0 / 8000: loss 25.112530
iteration 100 / 8000: loss 17.350509
iteration 200 / 8000: loss 13.614204
iteration 300 / 8000: loss 10.919821
iteration 400 / 8000: loss 8.829089
iteration 500 / 8000: loss 7.156296
iteration 600 / 8000: loss 5.996938
iteration 700 / 8000: loss 4.977440
iteration 800 / 8000: loss 4.342073
iteration 900 / 8000: loss 3.676522
	---- FINISHED batch size: 8.000000e+02 learning rate: 1.000000e-06 reg: 1.000000e+06------
iteration 0 / 8000: loss 102.680037
iteration 100 / 8000: loss 29.518375
iteration 200 / 8000: loss 9.672111
iteration 300 / 8000: loss 4.102391
iteration 400 / 8000: loss 2.514327
iteration 500 / 8000: loss 2.073072
iteration 600 / 8000: loss 1.982626
	---- FINISHED batch size: 8.000000e+02 learning rate: 1.000000e-06 reg: 5.000000e+06------
iteration 0 / 8000: loss 6.469341
	---- FINISHED batch size: 8.000000e+02 learning rate: 5.000000e-06 reg: 5.000000e+04------
iteration 0 / 8000: loss 7.460569
iteration 100 / 8000: loss 3.885314
iteration 200 / 8000: loss 3.314875
	---- FINISHED batch size: 8.000000e+02 learning rate: 5.000000e-06 reg: 1.000000e+05------
iteration 0 / 8000: loss 15.884587
iteration 100 / 8000: loss 6.981305
iteration 200 / 8000: loss 4.423158
	---- FINISHED batch size: 8.000000e+02 learning rate: 5.000000e-06 reg: 5.000000e+05------
iteration 0 / 8000: loss 24.543770
iteration 100 / 8000: loss 7.289155
iteration 200 / 8000: loss 3.318511
iteration 300 / 8000: loss 2.327821
	---- FINISHED batch size: 8.000000e+02 learning rate: 5.000000e-06 reg: 1.000000e+06------
iteration 0 / 8000: loss 101.974010
iteration 100 / 8000: loss 2.149933
	---- FINISHED batch size: 8.000000e+02 learning rate: 5.000000e-06 reg: 5.000000e+06------
iteration 0 / 8000: loss 6.273507
iteration 100 / 8000: loss 4.766091
iteration 200 / 8000: loss 4.282796
iteration 300 / 8000: loss 3.971190
	---- FINISHED batch size: 1.600000e+03 learning rate: 1.000000e-07 reg: 5.000000e+04------
iteration 0 / 8000: loss 6.620769
iteration 100 / 8000: loss 5.128974
	---- FINISHED batch size: 1.600000e+03 learning rate: 1.000000e-07 reg: 1.000000e+05------
iteration 0 / 8000: loss 10.465998
	---- FINISHED batch size: 1.600000e+03 learning rate: 1.000000e-07 reg: 5.000000e+05------
iteration 0 / 8000: loss 15.382590
iteration 100 / 8000: loss 13.383566
iteration 200 / 8000: loss 12.757160
	---- FINISHED batch size: 1.600000e+03 learning rate: 1.000000e-07 reg: 1.000000e+06------
iteration 0 / 8000: loss 53.573641
iteration 100 / 8000: loss 49.117647
iteration 200 / 8000: loss 45.692378
iteration 300 / 8000: loss 42.803075
iteration 400 / 8000: loss 40.089587
iteration 500 / 8000: loss 37.638714
iteration 600 / 8000: loss 35.264591
	---- FINISHED batch size: 1.600000e+03 learning rate: 1.000000e-07 reg: 5.000000e+06------
iteration 0 / 8000: loss 6.663642
iteration 100 / 8000: loss 3.693416
	---- FINISHED batch size: 1.600000e+03 learning rate: 5.000000e-07 reg: 5.000000e+04------
iteration 0 / 8000: loss 6.657189
iteration 100 / 8000: loss 3.940274
iteration 200 / 8000: loss 3.656281
iteration 300 / 8000: loss 3.436922
	---- FINISHED batch size: 1.600000e+03 learning rate: 5.000000e-07 reg: 1.000000e+05------
iteration 0 / 8000: loss 11.137859
iteration 100 / 8000: loss 7.655310
iteration 200 / 8000: loss 7.149456
	---- FINISHED batch size: 1.600000e+03 learning rate: 5.000000e-07 reg: 5.000000e+05------
iteration 0 / 8000: loss 14.910747
iteration 100 / 8000: loss 11.879696
iteration 200 / 8000: loss 10.940762
	---- FINISHED batch size: 1.600000e+03 learning rate: 5.000000e-07 reg: 1.000000e+06------
iteration 0 / 8000: loss 53.156126
iteration 100 / 8000: loss 37.668544
iteration 200 / 8000: loss 27.793698
iteration 300 / 8000: loss 20.621483
iteration 400 / 8000: loss 15.524705
iteration 500 / 8000: loss 11.750012
iteration 600 / 8000: loss 9.094332
iteration 700 / 8000: loss 7.127216
iteration 800 / 8000: loss 5.643625
	---- FINISHED batch size: 1.600000e+03 learning rate: 5.000000e-07 reg: 5.000000e+06------
iteration 0 / 8000: loss 6.282626
iteration 100 / 8000: loss 3.337076
iteration 200 / 8000: loss 2.938626
iteration 300 / 8000: loss 2.794412
iteration 400 / 8000: loss 2.728745
iteration 500 / 8000: loss 2.656746
iteration 600 / 8000: loss 2.613428
	---- FINISHED batch size: 1.600000e+03 learning rate: 1.000000e-06 reg: 5.000000e+04------
iteration 0 / 8000: loss 7.490815
iteration 100 / 8000: loss 3.698244
	---- FINISHED batch size: 1.600000e+03 learning rate: 1.000000e-06 reg: 1.000000e+05------
iteration 0 / 8000: loss 10.209260
iteration 100 / 8000: loss 7.083865
	---- FINISHED batch size: 1.600000e+03 learning rate: 1.000000e-06 reg: 5.000000e+05------
iteration 0 / 8000: loss 14.515714
iteration 100 / 8000: loss 11.100598
iteration 200 / 8000: loss 9.665487
iteration 300 / 8000: loss 8.536189
iteration 400 / 8000: loss 7.666264
	---- FINISHED batch size: 1.600000e+03 learning rate: 1.000000e-06 reg: 1.000000e+06------
iteration 0 / 8000: loss 53.417618
iteration 100 / 8000: loss 27.521170
iteration 200 / 8000: loss 15.364466
iteration 300 / 8000: loss 9.028803
iteration 400 / 8000: loss 5.627663
iteration 500 / 8000: loss 3.863926
iteration 600 / 8000: loss 2.903538
	---- FINISHED batch size: 1.600000e+03 learning rate: 1.000000e-06 reg: 5.000000e+06------
iteration 0 / 8000: loss 6.719681
	---- FINISHED batch size: 1.600000e+03 learning rate: 5.000000e-06 reg: 5.000000e+04------
iteration 0 / 8000: loss 7.660329
iteration 100 / 8000: loss 3.071579
	---- FINISHED batch size: 1.600000e+03 learning rate: 5.000000e-06 reg: 1.000000e+05------
iteration 0 / 8000: loss 10.728068
iteration 100 / 8000: loss 5.594179
iteration 200 / 8000: loss 4.410200
iteration 300 / 8000: loss 3.614774
	---- FINISHED batch size: 1.600000e+03 learning rate: 5.000000e-06 reg: 5.000000e+05------
iteration 0 / 8000: loss 15.382311
iteration 100 / 8000: loss 6.924433
iteration 200 / 8000: loss 4.440982
iteration 300 / 8000: loss 3.146793
iteration 400 / 8000: loss 2.460969
iteration 500 / 8000: loss 2.125955
	---- FINISHED batch size: 1.600000e+03 learning rate: 5.000000e-06 reg: 1.000000e+06------
iteration 0 / 8000: loss 53.509095
iteration 100 / 8000: loss 3.872534
	---- FINISHED batch size: 1.600000e+03 learning rate: 5.000000e-06 reg: 5.000000e+06------
iteration 0 / 8000: loss 6.223421
iteration 100 / 8000: loss 4.456457
iteration 200 / 8000: loss 3.969253
	---- FINISHED batch size: 3.200000e+03 learning rate: 1.000000e-07 reg: 5.000000e+04------
iteration 0 / 8000: loss 6.011960
iteration 100 / 8000: loss 4.784926
	---- FINISHED batch size: 3.200000e+03 learning rate: 1.000000e-07 reg: 1.000000e+05------
iteration 0 / 8000: loss 8.073119
iteration 100 / 8000: loss 6.234029
iteration 200 / 8000: loss 5.848924
	---- FINISHED batch size: 3.200000e+03 learning rate: 1.000000e-07 reg: 5.000000e+05------
iteration 0 / 8000: loss 10.131812
iteration 100 / 8000: loss 8.803943
iteration 200 / 8000: loss 8.306299
	---- FINISHED batch size: 3.200000e+03 learning rate: 1.000000e-07 reg: 1.000000e+06------
iteration 0 / 8000: loss 29.148353
iteration 100 / 8000: loss 26.997487
iteration 200 / 8000: loss 25.637878
	---- FINISHED batch size: 3.200000e+03 learning rate: 1.000000e-07 reg: 5.000000e+06------
iteration 0 / 8000: loss 6.045184
	---- FINISHED batch size: 3.200000e+03 learning rate: 5.000000e-07 reg: 5.000000e+04------
iteration 0 / 8000: loss 5.159122
	---- FINISHED batch size: 3.200000e+03 learning rate: 5.000000e-07 reg: 1.000000e+05------
iteration 0 / 8000: loss 8.702634
iteration 100 / 8000: loss 5.322098
iteration 200 / 8000: loss 4.956999
iteration 300 / 8000: loss 4.816676
	---- FINISHED batch size: 3.200000e+03 learning rate: 5.000000e-07 reg: 5.000000e+05------
iteration 0 / 8000: loss 10.462790
iteration 100 / 8000: loss 7.565854
iteration 200 / 8000: loss 7.087636
	---- FINISHED batch size: 3.200000e+03 learning rate: 5.000000e-07 reg: 1.000000e+06------
iteration 0 / 8000: loss 29.946653
iteration 100 / 8000: loss 23.069476
iteration 200 / 8000: loss 19.654369
iteration 300 / 8000: loss 16.917718
iteration 400 / 8000: loss 14.620049
iteration 500 / 8000: loss 12.658835
iteration 600 / 8000: loss 11.049573
	---- FINISHED batch size: 3.200000e+03 learning rate: 5.000000e-07 reg: 5.000000e+06------
iteration 0 / 8000: loss 6.000183
	---- FINISHED batch size: 3.200000e+03 learning rate: 1.000000e-06 reg: 5.000000e+04------
iteration 0 / 8000: loss 5.807936
iteration 100 / 8000: loss 3.188595
iteration 200 / 8000: loss 2.969377
	---- FINISHED batch size: 3.200000e+03 learning rate: 1.000000e-06 reg: 1.000000e+05------
iteration 0 / 8000: loss 7.793664
	---- FINISHED batch size: 3.200000e+03 learning rate: 1.000000e-06 reg: 5.000000e+05------
iteration 0 / 8000: loss 10.291054
iteration 100 / 8000: loss 7.175770
iteration 200 / 8000: loss 6.600525
iteration 300 / 8000: loss 6.073453
	---- FINISHED batch size: 3.200000e+03 learning rate: 1.000000e-06 reg: 1.000000e+06------
iteration 0 / 8000: loss 30.223084
iteration 100 / 8000: loss 19.655896
iteration 200 / 8000: loss 14.601041
iteration 300 / 8000: loss 11.057904
iteration 400 / 8000: loss 8.473337
iteration 500 / 8000: loss 6.651915
iteration 600 / 8000: loss 5.295993
iteration 700 / 8000: loss 4.364447
	---- FINISHED batch size: 3.200000e+03 learning rate: 1.000000e-06 reg: 5.000000e+06------
iteration 0 / 8000: loss 5.318840
iteration 100 / 8000: loss 2.370218
	---- FINISHED batch size: 3.200000e+03 learning rate: 5.000000e-06 reg: 5.000000e+04------
iteration 0 / 8000: loss 5.878458
	---- FINISHED batch size: 3.200000e+03 learning rate: 5.000000e-06 reg: 1.000000e+05------
iteration 0 / 8000: loss 8.378551
iteration 100 / 8000: loss 4.097886
iteration 200 / 8000: loss 3.587755
	---- FINISHED batch size: 3.200000e+03 learning rate: 5.000000e-06 reg: 5.000000e+05------
iteration 0 / 8000: loss 10.223191
iteration 100 / 8000: loss 5.471038
	---- FINISHED batch size: 3.200000e+03 learning rate: 5.000000e-06 reg: 1.000000e+06------
iteration 0 / 8000: loss 29.375819
iteration 100 / 8000: loss 6.645411
iteration 200 / 8000: loss 2.941742
iteration 300 / 8000: loss 2.055294
	---- FINISHED batch size: 3.200000e+03 learning rate: 5.000000e-06 reg: 5.000000e+06------
iteration 0 / 8000: loss 6.214661
iteration 100 / 8000: loss 4.172812
iteration 200 / 8000: loss 3.711838
	---- FINISHED batch size: 6.400000e+03 learning rate: 1.000000e-07 reg: 5.000000e+04------
iteration 0 / 8000: loss 5.140604
iteration 100 / 8000: loss 4.043024
iteration 200 / 8000: loss 3.745727
	---- FINISHED batch size: 6.400000e+03 learning rate: 1.000000e-07 reg: 1.000000e+05------
iteration 0 / 8000: loss 6.452926
iteration 100 / 8000: loss 5.145388
	---- FINISHED batch size: 6.400000e+03 learning rate: 1.000000e-07 reg: 5.000000e+05------
iteration 0 / 8000: loss 8.090229
iteration 100 / 8000: loss 6.329019
	---- FINISHED batch size: 6.400000e+03 learning rate: 1.000000e-07 reg: 1.000000e+06------
iteration 0 / 8000: loss 16.971979
iteration 100 / 8000: loss 15.479315
iteration 200 / 8000: loss 14.902727
	---- FINISHED batch size: 6.400000e+03 learning rate: 1.000000e-07 reg: 5.000000e+06------
iteration 0 / 8000: loss 5.442985
	---- FINISHED batch size: 6.400000e+03 learning rate: 5.000000e-07 reg: 5.000000e+04------
iteration 0 / 8000: loss 5.534665
iteration 100 / 8000: loss 3.261131
	---- FINISHED batch size: 6.400000e+03 learning rate: 5.000000e-07 reg: 1.000000e+05------
iteration 0 / 8000: loss 6.735919
iteration 100 / 8000: loss 4.290967
iteration 200 / 8000: loss 3.893605
iteration 300 / 8000: loss 3.751280
iteration 400 / 8000: loss 3.588638
	---- FINISHED batch size: 6.400000e+03 learning rate: 5.000000e-07 reg: 5.000000e+05------
iteration 0 / 8000: loss 7.922417
iteration 100 / 8000: loss 5.357012
	---- FINISHED batch size: 6.400000e+03 learning rate: 5.000000e-07 reg: 1.000000e+06------
iteration 0 / 8000: loss 17.844965
iteration 100 / 8000: loss 13.978602
iteration 200 / 8000: loss 12.800091
	---- FINISHED batch size: 6.400000e+03 learning rate: 5.000000e-07 reg: 5.000000e+06------
iteration 0 / 8000: loss 7.497566
iteration 100 / 8000: loss 2.846455
	---- FINISHED batch size: 6.400000e+03 learning rate: 1.000000e-06 reg: 5.000000e+04------
iteration 0 / 8000: loss 6.522767
iteration 100 / 8000: loss 2.940644
iteration 200 / 8000: loss 2.728816
iteration 300 / 8000: loss 2.562241
	---- FINISHED batch size: 6.400000e+03 learning rate: 1.000000e-06 reg: 1.000000e+05------
iteration 0 / 8000: loss 7.670288
	---- FINISHED batch size: 6.400000e+03 learning rate: 1.000000e-06 reg: 5.000000e+05------
iteration 0 / 8000: loss 8.108408
iteration 100 / 8000: loss 4.961030
	---- FINISHED batch size: 6.400000e+03 learning rate: 1.000000e-06 reg: 1.000000e+06------
iteration 0 / 8000: loss 17.324913
iteration 100 / 8000: loss 12.698694
iteration 200 / 8000: loss 10.848872
iteration 300 / 8000: loss 9.396200
iteration 400 / 8000: loss 8.201606
iteration 500 / 8000: loss 7.199953
	---- FINISHED batch size: 6.400000e+03 learning rate: 1.000000e-06 reg: 5.000000e+06------
iteration 0 / 8000: loss 6.369015
	---- FINISHED batch size: 6.400000e+03 learning rate: 5.000000e-06 reg: 5.000000e+04------
iteration 0 / 8000: loss 5.196653
	---- FINISHED batch size: 6.400000e+03 learning rate: 5.000000e-06 reg: 1.000000e+05------
iteration 0 / 8000: loss 6.361227
iteration 100 / 8000: loss 3.225787
iteration 200 / 8000: loss 2.954925
iteration 300 / 8000: loss 2.768504
	---- FINISHED batch size: 6.400000e+03 learning rate: 5.000000e-06 reg: 5.000000e+05------
iteration 0 / 8000: loss 8.189860
	---- FINISHED batch size: 6.400000e+03 learning rate: 5.000000e-06 reg: 1.000000e+06------
iteration 0 / 8000: loss 17.211863
iteration 100 / 8000: loss 7.271551
iteration 200 / 8000: loss 4.209580
iteration 300 / 8000: loss 2.873908
iteration 400 / 8000: loss 2.275867
	---- FINISHED batch size: 6.400000e+03 learning rate: 5.000000e-06 reg: 5.000000e+06------
**********results for 3.8*************
bs 1.000000e+02 iterations 2.347000e+03 lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.277898 val accuracy: 0.290000
bs 1.000000e+02 iterations 2.260000e+02 lr 1.000000e-07 reg 1.000000e+05 train accuracy: 0.172776 val accuracy: 0.185000
bs 1.000000e+02 iterations 1.575000e+03 lr 1.000000e-07 reg 5.000000e+05 train accuracy: 0.302184 val accuracy: 0.300000
bs 1.000000e+02 iterations 1.107000e+03 lr 1.000000e-07 reg 1.000000e+06 train accuracy: 0.297061 val accuracy: 0.328000
bs 1.000000e+02 iterations 7.550000e+02 lr 1.000000e-07 reg 5.000000e+06 train accuracy: 0.322020 val accuracy: 0.328000
bs 1.000000e+02 iterations 5.830000e+02 lr 5.000000e-07 reg 5.000000e+04 train accuracy: 0.277102 val accuracy: 0.268000
bs 1.000000e+02 iterations 1.950000e+02 lr 5.000000e-07 reg 1.000000e+05 train accuracy: 0.232694 val accuracy: 0.239000
bs 1.000000e+02 iterations 5.430000e+02 lr 5.000000e-07 reg 5.000000e+05 train accuracy: 0.348878 val accuracy: 0.363000
bs 1.000000e+02 iterations 4.610000e+02 lr 5.000000e-07 reg 1.000000e+06 train accuracy: 0.355449 val accuracy: 0.371000
bs 1.000000e+02 iterations 7.800000e+02 lr 5.000000e-07 reg 5.000000e+06 train accuracy: 0.312653 val accuracy: 0.324000
bs 1.000000e+02 iterations 6.900000e+01 lr 1.000000e-06 reg 5.000000e+04 train accuracy: 0.218082 val accuracy: 0.215000
bs 1.000000e+02 iterations 6.810000e+02 lr 1.000000e-06 reg 1.000000e+05 train accuracy: 0.352020 val accuracy: 0.334000
bs 1.000000e+02 iterations 5.360000e+02 lr 1.000000e-06 reg 5.000000e+05 train accuracy: 0.376143 val accuracy: 0.394000
bs 1.000000e+02 iterations 5.780000e+02 lr 1.000000e-06 reg 1.000000e+06 train accuracy: 0.362163 val accuracy: 0.369000
bs 1.000000e+02 iterations 2.410000e+02 lr 1.000000e-06 reg 5.000000e+06 train accuracy: 0.298673 val accuracy: 0.299000
bs 1.000000e+02 iterations 8.670000e+02 lr 5.000000e-06 reg 5.000000e+04 train accuracy: 0.342980 val accuracy: 0.355000
bs 1.000000e+02 iterations 4.530000e+02 lr 5.000000e-06 reg 1.000000e+05 train accuracy: 0.353367 val accuracy: 0.358000
bs 1.000000e+02 iterations 2.630000e+02 lr 5.000000e-06 reg 5.000000e+05 train accuracy: 0.285082 val accuracy: 0.284000
bs 1.000000e+02 iterations 2.052000e+03 lr 5.000000e-06 reg 1.000000e+06 train accuracy: 0.304796 val accuracy: 0.311000
bs 1.000000e+02 iterations 4.960000e+02 lr 5.000000e-06 reg 5.000000e+06 train accuracy: 0.174224 val accuracy: 0.168000
bs 2.000000e+02 iterations 4.790000e+02 lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.204857 val accuracy: 0.196000
bs 2.000000e+02 iterations 4.090000e+02 lr 1.000000e-07 reg 1.000000e+05 train accuracy: 0.192959 val accuracy: 0.203000
bs 2.000000e+02 iterations 1.170000e+02 lr 1.000000e-07 reg 5.000000e+05 train accuracy: 0.158980 val accuracy: 0.151000
bs 2.000000e+02 iterations 1.335000e+03 lr 1.000000e-07 reg 1.000000e+06 train accuracy: 0.282980 val accuracy: 0.296000
bs 2.000000e+02 iterations 1.326000e+03 lr 1.000000e-07 reg 5.000000e+06 train accuracy: 0.347510 val accuracy: 0.353000
bs 2.000000e+02 iterations 1.350000e+02 lr 5.000000e-07 reg 5.000000e+04 train accuracy: 0.214020 val accuracy: 0.225000
bs 2.000000e+02 iterations 5.530000e+02 lr 5.000000e-07 reg 1.000000e+05 train accuracy: 0.275673 val accuracy: 0.282000
bs 2.000000e+02 iterations 1.005000e+03 lr 5.000000e-07 reg 5.000000e+05 train accuracy: 0.368388 val accuracy: 0.355000
bs 2.000000e+02 iterations 7.640000e+02 lr 5.000000e-07 reg 1.000000e+06 train accuracy: 0.376449 val accuracy: 0.389000
bs 2.000000e+02 iterations 3.990000e+02 lr 5.000000e-07 reg 5.000000e+06 train accuracy: 0.352143 val accuracy: 0.371000
bs 2.000000e+02 iterations 2.800000e+02 lr 1.000000e-06 reg 5.000000e+04 train accuracy: 0.273592 val accuracy: 0.273000
bs 2.000000e+02 iterations 9.300000e+01 lr 1.000000e-06 reg 1.000000e+05 train accuracy: 0.220204 val accuracy: 0.228000
bs 2.000000e+02 iterations 6.610000e+02 lr 1.000000e-06 reg 5.000000e+05 train accuracy: 0.383245 val accuracy: 0.385000
bs 2.000000e+02 iterations 1.138000e+03 lr 1.000000e-06 reg 1.000000e+06 train accuracy: 0.379286 val accuracy: 0.379000
bs 2.000000e+02 iterations 1.750000e+02 lr 1.000000e-06 reg 5.000000e+06 train accuracy: 0.348286 val accuracy: 0.354000
bs 2.000000e+02 iterations 3.510000e+02 lr 5.000000e-06 reg 5.000000e+04 train accuracy: 0.364694 val accuracy: 0.360000
bs 2.000000e+02 iterations 4.800000e+01 lr 5.000000e-06 reg 1.000000e+05 train accuracy: 0.263980 val accuracy: 0.263000
bs 2.000000e+02 iterations 6.180000e+02 lr 5.000000e-06 reg 5.000000e+05 train accuracy: 0.326245 val accuracy: 0.320000
bs 2.000000e+02 iterations 2.490000e+02 lr 5.000000e-06 reg 1.000000e+06 train accuracy: 0.341041 val accuracy: 0.351000
bs 2.000000e+02 iterations 1.600000e+02 lr 5.000000e-06 reg 5.000000e+06 train accuracy: 0.270551 val accuracy: 0.281000
bs 4.000000e+02 iterations 4.920000e+02 lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.193102 val accuracy: 0.195000
bs 4.000000e+02 iterations 1.076000e+03 lr 1.000000e-07 reg 1.000000e+05 train accuracy: 0.224388 val accuracy: 0.253000
bs 4.000000e+02 iterations 1.370000e+02 lr 1.000000e-07 reg 5.000000e+05 train accuracy: 0.146122 val accuracy: 0.135000
bs 4.000000e+02 iterations 1.560000e+02 lr 1.000000e-07 reg 1.000000e+06 train accuracy: 0.160000 val accuracy: 0.172000
bs 4.000000e+02 iterations 1.508000e+03 lr 1.000000e-07 reg 5.000000e+06 train accuracy: 0.343898 val accuracy: 0.347000
bs 4.000000e+02 iterations 1.350000e+02 lr 5.000000e-07 reg 5.000000e+04 train accuracy: 0.223571 val accuracy: 0.234000
bs 4.000000e+02 iterations 3.100000e+02 lr 5.000000e-07 reg 1.000000e+05 train accuracy: 0.249816 val accuracy: 0.279000
bs 4.000000e+02 iterations 4.250000e+02 lr 5.000000e-07 reg 5.000000e+05 train accuracy: 0.280408 val accuracy: 0.295000
bs 4.000000e+02 iterations 8.740000e+02 lr 5.000000e-07 reg 1.000000e+06 train accuracy: 0.361408 val accuracy: 0.367000
bs 4.000000e+02 iterations 4.890000e+02 lr 5.000000e-07 reg 5.000000e+06 train accuracy: 0.368204 val accuracy: 0.368000
bs 4.000000e+02 iterations 1.150000e+02 lr 1.000000e-06 reg 5.000000e+04 train accuracy: 0.244449 val accuracy: 0.241000
bs 4.000000e+02 iterations 1.150000e+02 lr 1.000000e-06 reg 1.000000e+05 train accuracy: 0.235959 val accuracy: 0.257000
bs 4.000000e+02 iterations 4.120000e+02 lr 1.000000e-06 reg 5.000000e+05 train accuracy: 0.327673 val accuracy: 0.334000
bs 4.000000e+02 iterations 8.610000e+02 lr 1.000000e-06 reg 1.000000e+06 train accuracy: 0.393449 val accuracy: 0.398000
bs 4.000000e+02 iterations 2.260000e+02 lr 1.000000e-06 reg 5.000000e+06 train accuracy: 0.363735 val accuracy: 0.367000
bs 4.000000e+02 iterations 2.240000e+02 lr 5.000000e-06 reg 5.000000e+04 train accuracy: 0.330122 val accuracy: 0.330000
bs 4.000000e+02 iterations 1.150000e+02 lr 5.000000e-06 reg 1.000000e+05 train accuracy: 0.305673 val accuracy: 0.305000
bs 4.000000e+02 iterations 2.130000e+02 lr 5.000000e-06 reg 5.000000e+05 train accuracy: 0.371408 val accuracy: 0.376000
bs 4.000000e+02 iterations 1.860000e+02 lr 5.000000e-06 reg 1.000000e+06 train accuracy: 0.357816 val accuracy: 0.350000
bs 4.000000e+02 iterations 2.190000e+02 lr 5.000000e-06 reg 5.000000e+06 train accuracy: 0.286020 val accuracy: 0.288000
bs 8.000000e+02 iterations 2.200000e+01 lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.112429 val accuracy: 0.101000
bs 8.000000e+02 iterations 1.600000e+02 lr 1.000000e-07 reg 1.000000e+05 train accuracy: 0.162653 val accuracy: 0.162000
bs 8.000000e+02 iterations 1.810000e+02 lr 1.000000e-07 reg 5.000000e+05 train accuracy: 0.155286 val accuracy: 0.153000
bs 8.000000e+02 iterations 2.650000e+02 lr 1.000000e-07 reg 1.000000e+06 train accuracy: 0.175122 val accuracy: 0.165000
bs 8.000000e+02 iterations 1.717000e+03 lr 1.000000e-07 reg 5.000000e+06 train accuracy: 0.319592 val accuracy: 0.334000
bs 8.000000e+02 iterations 4.100000e+02 lr 5.000000e-07 reg 5.000000e+04 train accuracy: 0.256367 val accuracy: 0.274000
bs 8.000000e+02 iterations 6.800000e+01 lr 5.000000e-07 reg 1.000000e+05 train accuracy: 0.181163 val accuracy: 0.184000
bs 8.000000e+02 iterations 3.780000e+02 lr 5.000000e-07 reg 5.000000e+05 train accuracy: 0.268571 val accuracy: 0.287000
bs 8.000000e+02 iterations 6.980000e+02 lr 5.000000e-07 reg 1.000000e+06 train accuracy: 0.317633 val accuracy: 0.318000
bs 8.000000e+02 iterations 6.970000e+02 lr 5.000000e-07 reg 5.000000e+06 train accuracy: 0.376327 val accuracy: 0.388000
bs 8.000000e+02 iterations 1.780000e+02 lr 1.000000e-06 reg 5.000000e+04 train accuracy: 0.251286 val accuracy: 0.238000
bs 8.000000e+02 iterations 1.350000e+02 lr 1.000000e-06 reg 1.000000e+05 train accuracy: 0.247939 val accuracy: 0.279000
bs 8.000000e+02 iterations 1.780000e+02 lr 1.000000e-06 reg 5.000000e+05 train accuracy: 0.265939 val accuracy: 0.271000
bs 8.000000e+02 iterations 9.860000e+02 lr 1.000000e-06 reg 1.000000e+06 train accuracy: 0.394918 val accuracy: 0.402000
bs 8.000000e+02 iterations 6.110000e+02 lr 1.000000e-06 reg 5.000000e+06 train accuracy: 0.384980 val accuracy: 0.402000
bs 8.000000e+02 iterations 6.600000e+01 lr 5.000000e-06 reg 5.000000e+04 train accuracy: 0.281265 val accuracy: 0.276000
bs 8.000000e+02 iterations 2.020000e+02 lr 5.000000e-06 reg 1.000000e+05 train accuracy: 0.335163 val accuracy: 0.333000
bs 8.000000e+02 iterations 2.050000e+02 lr 5.000000e-06 reg 5.000000e+05 train accuracy: 0.351245 val accuracy: 0.350000
bs 8.000000e+02 iterations 3.640000e+02 lr 5.000000e-06 reg 1.000000e+06 train accuracy: 0.380061 val accuracy: 0.374000
bs 8.000000e+02 iterations 1.420000e+02 lr 5.000000e-06 reg 5.000000e+06 train accuracy: 0.374367 val accuracy: 0.384000
bs 1.600000e+03 iterations 3.610000e+02 lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.178531 val accuracy: 0.184000
bs 1.600000e+03 iterations 1.850000e+02 lr 1.000000e-07 reg 1.000000e+05 train accuracy: 0.159265 val accuracy: 0.151000
bs 1.600000e+03 iterations 5.200000e+01 lr 1.000000e-07 reg 5.000000e+05 train accuracy: 0.110837 val accuracy: 0.102000
bs 1.600000e+03 iterations 2.610000e+02 lr 1.000000e-07 reg 1.000000e+06 train accuracy: 0.178612 val accuracy: 0.171000
bs 1.600000e+03 iterations 6.170000e+02 lr 1.000000e-07 reg 5.000000e+06 train accuracy: 0.198347 val accuracy: 0.207000
bs 1.600000e+03 iterations 1.470000e+02 lr 5.000000e-07 reg 5.000000e+04 train accuracy: 0.215286 val accuracy: 0.217000
bs 1.600000e+03 iterations 3.150000e+02 lr 5.000000e-07 reg 1.000000e+05 train accuracy: 0.250306 val accuracy: 0.229000
bs 1.600000e+03 iterations 2.270000e+02 lr 5.000000e-07 reg 5.000000e+05 train accuracy: 0.239673 val accuracy: 0.254000
bs 1.600000e+03 iterations 2.620000e+02 lr 5.000000e-07 reg 1.000000e+06 train accuracy: 0.252204 val accuracy: 0.278000
bs 1.600000e+03 iterations 8.280000e+02 lr 5.000000e-07 reg 5.000000e+06 train accuracy: 0.366122 val accuracy: 0.378000
bs 1.600000e+03 iterations 6.310000e+02 lr 1.000000e-06 reg 5.000000e+04 train accuracy: 0.311388 val accuracy: 0.295000
bs 1.600000e+03 iterations 1.940000e+02 lr 1.000000e-06 reg 1.000000e+05 train accuracy: 0.264918 val accuracy: 0.263000
bs 1.600000e+03 iterations 1.490000e+02 lr 1.000000e-06 reg 5.000000e+05 train accuracy: 0.249653 val accuracy: 0.269000
bs 1.600000e+03 iterations 4.500000e+02 lr 1.000000e-06 reg 1.000000e+06 train accuracy: 0.311061 val accuracy: 0.313000
bs 1.600000e+03 iterations 6.110000e+02 lr 1.000000e-06 reg 5.000000e+06 train accuracy: 0.389143 val accuracy: 0.391000
bs 1.600000e+03 iterations 3.000000e+01 lr 5.000000e-06 reg 5.000000e+04 train accuracy: 0.248388 val accuracy: 0.262000
bs 1.600000e+03 iterations 1.170000e+02 lr 5.000000e-06 reg 1.000000e+05 train accuracy: 0.312918 val accuracy: 0.330000
bs 1.600000e+03 iterations 3.280000e+02 lr 5.000000e-06 reg 5.000000e+05 train accuracy: 0.370469 val accuracy: 0.384000
bs 1.600000e+03 iterations 5.980000e+02 lr 5.000000e-06 reg 1.000000e+06 train accuracy: 0.398020 val accuracy: 0.395000
bs 1.600000e+03 iterations 1.590000e+02 lr 5.000000e-06 reg 5.000000e+06 train accuracy: 0.369959 val accuracy: 0.380000
bs 3.200000e+03 iterations 2.420000e+02 lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.180041 val accuracy: 0.180000
bs 3.200000e+03 iterations 1.280000e+02 lr 1.000000e-07 reg 1.000000e+05 train accuracy: 0.136204 val accuracy: 0.142000
bs 3.200000e+03 iterations 2.680000e+02 lr 1.000000e-07 reg 5.000000e+05 train accuracy: 0.176755 val accuracy: 0.203000
bs 3.200000e+03 iterations 2.620000e+02 lr 1.000000e-07 reg 1.000000e+06 train accuracy: 0.178143 val accuracy: 0.182000
bs 3.200000e+03 iterations 2.270000e+02 lr 1.000000e-07 reg 5.000000e+06 train accuracy: 0.167224 val accuracy: 0.176000
bs 3.200000e+03 iterations 8.000000e+01 lr 5.000000e-07 reg 5.000000e+04 train accuracy: 0.197714 val accuracy: 0.202000
bs 3.200000e+03 iterations 6.200000e+01 lr 5.000000e-07 reg 1.000000e+05 train accuracy: 0.188735 val accuracy: 0.213000
bs 3.200000e+03 iterations 3.740000e+02 lr 5.000000e-07 reg 5.000000e+05 train accuracy: 0.259776 val accuracy: 0.278000
bs 3.200000e+03 iterations 2.500000e+02 lr 5.000000e-07 reg 1.000000e+06 train accuracy: 0.251327 val accuracy: 0.276000
bs 3.200000e+03 iterations 6.720000e+02 lr 5.000000e-07 reg 5.000000e+06 train accuracy: 0.316041 val accuracy: 0.330000
bs 3.200000e+03 iterations 6.400000e+01 lr 1.000000e-06 reg 5.000000e+04 train accuracy: 0.210592 val accuracy: 0.209000
bs 3.200000e+03 iterations 2.010000e+02 lr 1.000000e-06 reg 1.000000e+05 train accuracy: 0.255878 val accuracy: 0.245000
bs 3.200000e+03 iterations 7.700000e+01 lr 1.000000e-06 reg 5.000000e+05 train accuracy: 0.226571 val accuracy: 0.223000
bs 3.200000e+03 iterations 3.940000e+02 lr 1.000000e-06 reg 1.000000e+06 train accuracy: 0.295265 val accuracy: 0.297000
bs 3.200000e+03 iterations 7.570000e+02 lr 1.000000e-06 reg 5.000000e+06 train accuracy: 0.385102 val accuracy: 0.395000
bs 3.200000e+03 iterations 1.270000e+02 lr 5.000000e-06 reg 5.000000e+04 train accuracy: 0.313857 val accuracy: 0.303000
bs 3.200000e+03 iterations 9.800000e+01 lr 5.000000e-06 reg 1.000000e+05 train accuracy: 0.297388 val accuracy: 0.272000
bs 3.200000e+03 iterations 2.410000e+02 lr 5.000000e-06 reg 5.000000e+05 train accuracy: 0.352449 val accuracy: 0.357000
bs 3.200000e+03 iterations 1.940000e+02 lr 5.000000e-06 reg 1.000000e+06 train accuracy: 0.344857 val accuracy: 0.345000
bs 3.200000e+03 iterations 3.960000e+02 lr 5.000000e-06 reg 5.000000e+06 train accuracy: 0.387204 val accuracy: 0.389000
bs 6.400000e+03 iterations 2.350000e+02 lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.176204 val accuracy: 0.175000
bs 6.400000e+03 iterations 2.200000e+02 lr 1.000000e-07 reg 1.000000e+05 train accuracy: 0.180837 val accuracy: 0.188000
bs 6.400000e+03 iterations 1.200000e+02 lr 1.000000e-07 reg 5.000000e+05 train accuracy: 0.147959 val accuracy: 0.156000
bs 6.400000e+03 iterations 1.330000e+02 lr 1.000000e-07 reg 1.000000e+06 train accuracy: 0.166122 val accuracy: 0.142000
bs 6.400000e+03 iterations 2.770000e+02 lr 1.000000e-07 reg 5.000000e+06 train accuracy: 0.187755 val accuracy: 0.169000
bs 6.400000e+03 iterations 4.500000e+01 lr 5.000000e-07 reg 5.000000e+04 train accuracy: 0.175347 val accuracy: 0.165000
bs 6.400000e+03 iterations 1.290000e+02 lr 5.000000e-07 reg 1.000000e+05 train accuracy: 0.211367 val accuracy: 0.222000
bs 6.400000e+03 iterations 4.780000e+02 lr 5.000000e-07 reg 5.000000e+05 train accuracy: 0.269653 val accuracy: 0.303000
bs 6.400000e+03 iterations 1.050000e+02 lr 5.000000e-07 reg 1.000000e+06 train accuracy: 0.201735 val accuracy: 0.192000
bs 6.400000e+03 iterations 2.600000e+02 lr 5.000000e-07 reg 5.000000e+06 train accuracy: 0.250980 val accuracy: 0.259000
bs 6.400000e+03 iterations 1.530000e+02 lr 1.000000e-06 reg 5.000000e+04 train accuracy: 0.249204 val accuracy: 0.249000
bs 6.400000e+03 iterations 3.490000e+02 lr 1.000000e-06 reg 1.000000e+05 train accuracy: 0.286918 val accuracy: 0.260000
bs 6.400000e+03 iterations 9.600000e+01 lr 1.000000e-06 reg 5.000000e+05 train accuracy: 0.227816 val accuracy: 0.230000
bs 6.400000e+03 iterations 1.250000e+02 lr 1.000000e-06 reg 1.000000e+06 train accuracy: 0.243000 val accuracy: 0.234000
bs 6.400000e+03 iterations 5.240000e+02 lr 1.000000e-06 reg 5.000000e+06 train accuracy: 0.328735 val accuracy: 0.314000
bs 6.400000e+03 iterations 1.000000e+02 lr 5.000000e-06 reg 5.000000e+04 train accuracy: 0.302878 val accuracy: 0.300000
bs 6.400000e+03 iterations 6.700000e+01 lr 5.000000e-06 reg 1.000000e+05 train accuracy: 0.282367 val accuracy: 0.295000
bs 6.400000e+03 iterations 3.620000e+02 lr 5.000000e-06 reg 5.000000e+05 train accuracy: 0.368796 val accuracy: 0.350000
bs 6.400000e+03 iterations 9.100000e+01 lr 5.000000e-06 reg 1.000000e+06 train accuracy: 0.294490 val accuracy: 0.277000
bs 6.400000e+03 iterations 4.630000e+02 lr 5.000000e-06 reg 5.000000e+06 train accuracy: 0.391633 val accuracy: 0.389000
best validation accuracy achieved during cross-validation: 0.402000
	 with bs 8.000000e+02 iterations 9.860000e+02 lr 1.000000e-06 reg 1.000000e+06
softmax on raw pixels final test set accuracy: 0.383700
