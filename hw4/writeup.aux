\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Kernelizing the perceptron}{1}}
\newlabel{eq:1.1}{{1}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}}{1}}
\newlabel{eq:1.2}{{2}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}}{1}}
\newlabel{eq:1.3}{{3}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}}{2}}
\newlabel{eq:1.4}{{4}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Fitting an SVM classifier by hand}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Support vector machines for binary classification}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Support vector machines}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}The hinge loss function and gradient}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Example dataset 1: impact of varying C}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces decision boundary with C=100\relax }}{3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:3.11}{{1}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces decision boundary with C=1\relax }}{4}}
\newlabel{fig:3.12}{{2}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3}Gaussian kernel}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Learning non-linear boundary using a Gaussian kernel\relax }}{5}}
\newlabel{fig:3.1_gb}{{3}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Example dataset 3: selecting hyper parameters for SVMs}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces decision boundary with best $C=0.1$ and best $\sigma = 0.1$\relax }}{6}}
\newlabel{fig:3.2}{{4}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Spam Classification with SVMs}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces How the performance on validation set changes with iteration. Here we set learning rate to 0.1 and vary C. We can see that the performance of c=0.05,0.1 and 0.5 are similar, while when C=1 the model is overfitted.\relax }}{7}}
\newlabel{fig:3.31}{{5}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Set C to 0.1 and vary learning rate. According to this figure I think if we set learning rate to 0.1, 2000 iterations will be enough. \relax }}{7}}
\newlabel{fig:3.31}{{6}{7}}
